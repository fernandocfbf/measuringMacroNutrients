{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib.pyplot as plt\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from dnn_app_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pizza images\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "973it [00:02, 326.72it/s]\n",
      "525it [00:01, 395.21it/s]\n"
     ]
    }
   ],
   "source": [
    "x, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498, 3072)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y =  train_test_split(x, y, test_size=0.33, random_state=84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the neural-network architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#The first hidden layer will have 1024 nodes and the input layer 3072.\n",
    "model.add(Dense(1024, input_shape=(32*32*3,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 80\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 3072)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - 4s 68ms/step - loss: 0.6719 - accuracy: 0.6341 - val_loss: 0.6750 - val_accuracy: 0.6263\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.6246 - accuracy: 0.6851 - val_loss: 0.6783 - val_accuracy: 0.6263\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6360 - accuracy: 0.6688 - val_loss: 0.6932 - val_accuracy: 0.6263\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.6454 - accuracy: 0.6635 - val_loss: 0.6692 - val_accuracy: 0.6263\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.6322 - accuracy: 0.6727 - val_loss: 0.6693 - val_accuracy: 0.6263\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6326 - accuracy: 0.6660 - val_loss: 0.6591 - val_accuracy: 0.6263\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6514 - accuracy: 0.6170 - val_loss: 0.7044 - val_accuracy: 0.6263\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6267 - accuracy: 0.6803 - val_loss: 0.7394 - val_accuracy: 0.6263\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6386 - accuracy: 0.6522 - val_loss: 0.6577 - val_accuracy: 0.6465\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6217 - accuracy: 0.6777 - val_loss: 0.7116 - val_accuracy: 0.3899\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.6410 - accuracy: 0.6045 - val_loss: 0.6578 - val_accuracy: 0.6263\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.6379 - accuracy: 0.6493 - val_loss: 0.6375 - val_accuracy: 0.6263\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6363 - accuracy: 0.6522 - val_loss: 0.6450 - val_accuracy: 0.6626\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6225 - accuracy: 0.6742 - val_loss: 0.6393 - val_accuracy: 0.6626\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6265 - accuracy: 0.6583 - val_loss: 0.7167 - val_accuracy: 0.6263\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6261 - accuracy: 0.6512 - val_loss: 0.6418 - val_accuracy: 0.6263\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5945 - accuracy: 0.6785 - val_loss: 0.6313 - val_accuracy: 0.6263\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.6019 - accuracy: 0.6710 - val_loss: 0.6238 - val_accuracy: 0.6263\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5914 - accuracy: 0.6969 - val_loss: 0.6253 - val_accuracy: 0.6687\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6761 - val_loss: 0.6193 - val_accuracy: 0.6626\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6052 - accuracy: 0.6740 - val_loss: 0.6198 - val_accuracy: 0.6727\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6085 - accuracy: 0.6695 - val_loss: 0.6175 - val_accuracy: 0.6707\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.6024 - accuracy: 0.6879 - val_loss: 0.6323 - val_accuracy: 0.6263\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5759 - accuracy: 0.6964 - val_loss: 0.6116 - val_accuracy: 0.6242\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5863 - accuracy: 0.6760 - val_loss: 0.6440 - val_accuracy: 0.6263\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5838 - accuracy: 0.6987 - val_loss: 0.6579 - val_accuracy: 0.6263\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5806 - accuracy: 0.6954 - val_loss: 0.6436 - val_accuracy: 0.6646\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5931 - accuracy: 0.6706 - val_loss: 0.6156 - val_accuracy: 0.6242\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5751 - accuracy: 0.6835 - val_loss: 0.5951 - val_accuracy: 0.6687\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5752 - accuracy: 0.6959 - val_loss: 0.5938 - val_accuracy: 0.6727\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.5884 - accuracy: 0.6714 - val_loss: 0.6110 - val_accuracy: 0.7232\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5786 - accuracy: 0.7136 - val_loss: 0.5906 - val_accuracy: 0.6505\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5595 - accuracy: 0.7218 - val_loss: 0.5881 - val_accuracy: 0.6990\n",
      "Epoch 34/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5662 - accuracy: 0.7005 - val_loss: 0.5861 - val_accuracy: 0.6687\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5742 - accuracy: 0.7038 - val_loss: 0.5845 - val_accuracy: 0.7192\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5577 - accuracy: 0.7149 - val_loss: 0.5854 - val_accuracy: 0.7273\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5696 - accuracy: 0.7216 - val_loss: 0.5862 - val_accuracy: 0.6525\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5472 - accuracy: 0.7210 - val_loss: 0.5770 - val_accuracy: 0.7172\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5428 - accuracy: 0.7209 - val_loss: 0.5782 - val_accuracy: 0.7374\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5694 - accuracy: 0.6964 - val_loss: 0.5734 - val_accuracy: 0.6747\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5444 - accuracy: 0.7217 - val_loss: 0.5957 - val_accuracy: 0.6444\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5427 - accuracy: 0.7248 - val_loss: 0.5893 - val_accuracy: 0.6444\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5509 - accuracy: 0.6988 - val_loss: 0.6635 - val_accuracy: 0.6121\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5503 - accuracy: 0.7259 - val_loss: 0.5887 - val_accuracy: 0.7071\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5456 - accuracy: 0.7238 - val_loss: 0.5752 - val_accuracy: 0.6707\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5456 - accuracy: 0.7305 - val_loss: 0.7171 - val_accuracy: 0.6263\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5658 - accuracy: 0.7241 - val_loss: 0.6073 - val_accuracy: 0.6404\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5345 - accuracy: 0.7186 - val_loss: 0.5950 - val_accuracy: 0.6949\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5548 - accuracy: 0.7082 - val_loss: 0.5604 - val_accuracy: 0.7374\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5195 - accuracy: 0.7450 - val_loss: 0.7530 - val_accuracy: 0.6263\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5418 - accuracy: 0.7259 - val_loss: 0.6210 - val_accuracy: 0.6384\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5363 - accuracy: 0.7312 - val_loss: 0.5694 - val_accuracy: 0.6828\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5252 - accuracy: 0.7403 - val_loss: 0.5584 - val_accuracy: 0.7333\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5299 - accuracy: 0.7367 - val_loss: 0.6262 - val_accuracy: 0.6606\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5555 - accuracy: 0.7037 - val_loss: 0.5522 - val_accuracy: 0.7333\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5323 - accuracy: 0.7425 - val_loss: 0.6612 - val_accuracy: 0.6364\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5494 - accuracy: 0.7364 - val_loss: 0.5582 - val_accuracy: 0.6869\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.4948 - accuracy: 0.7649 - val_loss: 0.7132 - val_accuracy: 0.6263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5542 - accuracy: 0.7044 - val_loss: 0.5492 - val_accuracy: 0.7455\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5245 - accuracy: 0.7445 - val_loss: 0.5968 - val_accuracy: 0.6545\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5100 - accuracy: 0.7668 - val_loss: 0.5540 - val_accuracy: 0.7394\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5354 - accuracy: 0.7407 - val_loss: 0.5631 - val_accuracy: 0.6848\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5277 - accuracy: 0.7312 - val_loss: 0.5463 - val_accuracy: 0.7455\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.5258 - accuracy: 0.7338 - val_loss: 0.5471 - val_accuracy: 0.7434\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5006 - accuracy: 0.7498 - val_loss: 0.6367 - val_accuracy: 0.6404\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5041 - accuracy: 0.7424 - val_loss: 0.5724 - val_accuracy: 0.6788\n",
      "Epoch 67/80\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.5208 - accuracy: 0.7438 - val_loss: 0.6089 - val_accuracy: 0.6808\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5383 - accuracy: 0.7325 - val_loss: 0.5633 - val_accuracy: 0.7232\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5250 - accuracy: 0.7402 - val_loss: 0.5956 - val_accuracy: 0.6525\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5025 - accuracy: 0.7542 - val_loss: 0.5568 - val_accuracy: 0.7333\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.5311 - accuracy: 0.7486 - val_loss: 0.5621 - val_accuracy: 0.7273\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.4978 - accuracy: 0.7565 - val_loss: 0.5432 - val_accuracy: 0.7374\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5387 - accuracy: 0.7372 - val_loss: 0.5560 - val_accuracy: 0.6949\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5079 - accuracy: 0.7370 - val_loss: 0.6122 - val_accuracy: 0.6545\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.5076 - accuracy: 0.7620 - val_loss: 0.6287 - val_accuracy: 0.6465\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.4993 - accuracy: 0.7536 - val_loss: 0.5508 - val_accuracy: 0.7051\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.5035 - accuracy: 0.7459 - val_loss: 0.5442 - val_accuracy: 0.7293\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.5591 - accuracy: 0.7335 - val_loss: 0.5701 - val_accuracy: 0.6848\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.76 - 1s 24ms/step - loss: 0.5063 - accuracy: 0.7682 - val_loss: 0.5789 - val_accuracy: 0.7010\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4925 - accuracy: 0.7697 - val_loss: 0.5734 - val_accuracy: 0.6869\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(x= train_x, y=train_y, validation_data=(test_x, test_y), epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-731a7747f371>:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=test_x, batch_size=32)\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
